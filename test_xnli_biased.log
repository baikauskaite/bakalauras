Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 392702/392702 [00:13<00:00, 28578.08 examples/s]
Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5010/5010 [00:00<00:00, 21255.31 examples/s]
/home/viktorija/miniforge3/envs/flue/lib/python3.11/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
{'loss': 0.8313, 'grad_norm': 4.129291534423828, 'learning_rate': 1.9592568448500654e-05, 'epoch': 0.08}                                                                 
{'loss': 0.6778, 'grad_norm': 4.358623027801514, 'learning_rate': 1.9185951760104305e-05, 'epoch': 0.16}                                                                 
{'loss': 0.643, 'grad_norm': 3.7928061485290527, 'learning_rate': 1.8779335071707953e-05, 'epoch': 0.24}                                                                 
{'loss': 0.6214, 'grad_norm': 4.537097930908203, 'learning_rate': 1.8371903520208606e-05, 'epoch': 0.33}                                                                 
{'loss': 0.6052, 'grad_norm': 4.014148235321045, 'learning_rate': 1.796447196870926e-05, 'epoch': 0.41}                                                                  
{'loss': 0.5929, 'grad_norm': 3.4564435482025146, 'learning_rate': 1.755704041720991e-05, 'epoch': 0.49}                                                                 
{'loss': 0.581, 'grad_norm': 4.533057689666748, 'learning_rate': 1.7149608865710564e-05, 'epoch': 0.57}                                                                  
{'loss': 0.5797, 'grad_norm': 3.9740328788757324, 'learning_rate': 1.6742177314211213e-05, 'epoch': 0.65}                                                                
{'loss': 0.5766, 'grad_norm': 4.937413215637207, 'learning_rate': 1.6335560625814864e-05, 'epoch': 0.73}                                                                 
{'loss': 0.5613, 'grad_norm': 5.83162260055542, 'learning_rate': 1.5928129074315517e-05, 'epoch': 0.81}                                                                  
{'loss': 0.5673, 'grad_norm': 4.136536121368408, 'learning_rate': 1.552069752281617e-05, 'epoch': 0.9}                                                                   
{'loss': 0.5538, 'grad_norm': 5.992307186126709, 'learning_rate': 1.511326597131682e-05, 'epoch': 0.98}                                                                  
 25%|███████████████████████████████▊                                                                                               | 6136/24544 [14:17<43:07,  7.11it/sTrainer is attempting to log a value of "{'accuracy': 0.7980039920159681}" of type <class 'dict'> for key "eval/accuracy" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.
Trainer is attempting to log a value of "{'precision': 0.8102257244908708}" of type <class 'dict'> for key "eval/precision" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.
Trainer is attempting to log a value of "{'recall': 0.7980039920159681}" of type <class 'dict'> for key "eval/recall" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.
{'eval_loss': 0.5270313620567322, 'eval_accuracy': {'accuracy': 0.7980039920159681}, 'eval_precision': {'precision': 0.8102257244908708}, 'eval_recall': {'recall': 0.7980039920159681}, 'eval_runtime': 2.8793, 'eval_samples_per_second': 1740.007, 'eval_steps_per_second': 27.437, 'epoch': 1.0}                                              
{'loss': 0.5098, 'grad_norm': 3.6032373905181885, 'learning_rate': 1.4705834419817473e-05, 'epoch': 1.06}                                                                
{'loss': 0.4941, 'grad_norm': 4.578993320465088, 'learning_rate': 1.4298402868318124e-05, 'epoch': 1.14}                                                                 
{'loss': 0.4948, 'grad_norm': 3.2491025924682617, 'learning_rate': 1.3891786179921773e-05, 'epoch': 1.22}                                                                
{'loss': 0.4921, 'grad_norm': 5.057945251464844, 'learning_rate': 1.3484354628422427e-05, 'epoch': 1.3}                                                                  
{'loss': 0.4967, 'grad_norm': 4.799214839935303, 'learning_rate': 1.3076923076923078e-05, 'epoch': 1.39}                                                                 
{'loss': 0.492, 'grad_norm': 4.398763179779053, 'learning_rate': 1.2669491525423729e-05, 'epoch': 1.47}                                                                  
{'loss': 0.4936, 'grad_norm': 4.4336957931518555, 'learning_rate': 1.226205997392438e-05, 'epoch': 1.55}                                                                 
{'loss': 0.4854, 'grad_norm': 5.60568904876709, 'learning_rate': 1.1854628422425034e-05, 'epoch': 1.63}                                                                  
{'loss': 0.4887, 'grad_norm': 3.9243645668029785, 'learning_rate': 1.1447196870925685e-05, 'epoch': 1.71}                                                                
{'loss': 0.4745, 'grad_norm': 4.246050834655762, 'learning_rate': 1.1039765319426336e-05, 'epoch': 1.79}                                                                 
{'loss': 0.4803, 'grad_norm': 4.554559707641602, 'learning_rate': 1.063233376792699e-05, 'epoch': 1.87}                                                                  
{'loss': 0.4818, 'grad_norm': 5.322998523712158, 'learning_rate': 1.0224902216427641e-05, 'epoch': 1.96}                                                                 
 50%|███████████████████████████████████████████████████████████████                                                               | 12272/24544 [28:31<29:00,  7.05it/sTrainer is attempting to log a value of "{'accuracy': 0.8047904191616766}" of type <class 'dict'> for key "eval/accuracy" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.
Trainer is attempting to log a value of "{'precision': 0.8130096923522571}" of type <class 'dict'> for key "eval/precision" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.
Trainer is attempting to log a value of "{'recall': 0.8047904191616766}" of type <class 'dict'> for key "eval/recall" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.
{'eval_loss': 0.4978741705417633, 'eval_accuracy': {'accuracy': 0.8047904191616766}, 'eval_precision': {'precision': 0.8130096923522571}, 'eval_recall': {'recall': 0.8047904191616766}, 'eval_runtime': 2.8848, 'eval_samples_per_second': 1736.683, 'eval_steps_per_second': 27.385, 'epoch': 2.0}                                              
{'loss': 0.4541, 'grad_norm': 4.619243144989014, 'learning_rate': 9.818285528031292e-06, 'epoch': 2.04}                                                                  
{'loss': 0.4204, 'grad_norm': 3.625028371810913, 'learning_rate': 9.410853976531943e-06, 'epoch': 2.12}                                                                  
{'loss': 0.4245, 'grad_norm': 3.69404673576355, 'learning_rate': 9.003422425032596e-06, 'epoch': 2.2}                                                                    
{'loss': 0.4261, 'grad_norm': 5.235189437866211, 'learning_rate': 8.595990873533247e-06, 'epoch': 2.28}                                                                  
{'loss': 0.4145, 'grad_norm': 4.7282280921936035, 'learning_rate': 8.189374185136898e-06, 'epoch': 2.36}                                                                 
{'loss': 0.4207, 'grad_norm': 6.670897960662842, 'learning_rate': 7.781942633637549e-06, 'epoch': 2.44}                                                                  
{'loss': 0.4263, 'grad_norm': 6.753589153289795, 'learning_rate': 7.3745110821382015e-06, 'epoch': 2.53}                                                                 
{'loss': 0.4226, 'grad_norm': 5.7336859703063965, 'learning_rate': 6.967079530638852e-06, 'epoch': 2.61}                                                                 
{'loss': 0.4177, 'grad_norm': 5.2454915046691895, 'learning_rate': 6.559647979139505e-06, 'epoch': 2.69}                                                                 
{'loss': 0.4281, 'grad_norm': 4.7584052085876465, 'learning_rate': 6.1522164276401576e-06, 'epoch': 2.77}                                                                
{'loss': 0.4132, 'grad_norm': 4.200150489807129, 'learning_rate': 5.7447848761408084e-06, 'epoch': 2.85}                                                                 
{'loss': 0.4124, 'grad_norm': 4.250361442565918, 'learning_rate': 5.337353324641461e-06, 'epoch': 2.93}                                                                  
 75%|██████████████████████████████████████████████████████████████████████████████████████████████▌                               | 18408/24544 [42:47<14:29,  7.06it/sTrainer is attempting to log a value of "{'accuracy': 0.8093812375249501}" of type <class 'dict'> for key "eval/accuracy" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.
Trainer is attempting to log a value of "{'precision': 0.8178431920724775}" of type <class 'dict'> for key "eval/precision" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.
Trainer is attempting to log a value of "{'recall': 0.8093812375249501}" of type <class 'dict'> for key "eval/recall" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.
{'eval_loss': 0.5140936374664307, 'eval_accuracy': {'accuracy': 0.8093812375249501}, 'eval_precision': {'precision': 0.8178431920724775}, 'eval_recall': {'recall': 0.8093812375249501}, 'eval_runtime': 2.8828, 'eval_samples_per_second': 1737.865, 'eval_steps_per_second': 27.403, 'epoch': 3.0}                                              
{'loss': 0.408, 'grad_norm': 4.9573974609375, 'learning_rate': 4.929921773142112e-06, 'epoch': 3.01}                                                                     
{'loss': 0.3795, 'grad_norm': 6.166615962982178, 'learning_rate': 4.523305084745763e-06, 'epoch': 3.1}                                                                   
{'loss': 0.3721, 'grad_norm': 4.776215076446533, 'learning_rate': 4.115873533246415e-06, 'epoch': 3.18}                                                                  
{'loss': 0.3776, 'grad_norm': 4.994270324707031, 'learning_rate': 3.7084419817470666e-06, 'epoch': 3.26}                                                                 
{'loss': 0.3713, 'grad_norm': 5.2650556564331055, 'learning_rate': 3.3010104302477188e-06, 'epoch': 3.34}                                                                
{'loss': 0.3721, 'grad_norm': 4.794133186340332, 'learning_rate': 2.894393741851369e-06, 'epoch': 3.42}                                                                  
{'loss': 0.3735, 'grad_norm': 6.600529670715332, 'learning_rate': 2.4877770534550195e-06, 'epoch': 3.5}                                                                  
{'loss': 0.3801, 'grad_norm': 4.5092644691467285, 'learning_rate': 2.0803455019556717e-06, 'epoch': 3.59}                                                                
{'loss': 0.3743, 'grad_norm': 7.219121932983398, 'learning_rate': 1.6729139504563236e-06, 'epoch': 3.67}                                                                 
{'loss': 0.3745, 'grad_norm': 9.321435928344727, 'learning_rate': 1.2654823989569754e-06, 'epoch': 3.75}                                                                 
{'loss': 0.3733, 'grad_norm': 5.054193496704102, 'learning_rate': 8.580508474576271e-07, 'epoch': 3.83}                                                                  
{'loss': 0.3752, 'grad_norm': 4.601981163024902, 'learning_rate': 4.5061929595827906e-07, 'epoch': 3.91}                                                                 
{'loss': 0.3725, 'grad_norm': 7.0260820388793945, 'learning_rate': 4.31877444589309e-08, 'epoch': 3.99}                                                                  
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24544/24544 [58:02<00:00,  6.60it/sTrainer is attempting to log a value of "{'accuracy': 0.8147704590818363}" of type <class 'dict'> for key "eval/accuracy" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.
Trainer is attempting to log a value of "{'precision': 0.8199175878410273}" of type <class 'dict'> for key "eval/precision" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.
Trainer is attempting to log a value of "{'recall': 0.8147704590818363}" of type <class 'dict'> for key "eval/recall" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.
{'eval_loss': 0.5201127529144287, 'eval_accuracy': {'accuracy': 0.8147704590818363}, 'eval_precision': {'precision': 0.8199175878410273}, 'eval_recall': {'recall': 0.8147704590818363}, 'eval_runtime': 3.1018, 'eval_samples_per_second': 1615.206, 'eval_steps_per_second': 25.469, 'epoch': 4.0}                                              
{'train_runtime': 3486.1536, 'train_samples_per_second': 450.585, 'train_steps_per_second': 7.04, 'train_loss': 0.4744893092530958, 'epoch': 4.0}                        
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24544/24544 [58:06<00:00,  7.04it/s]
 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋   | 77/79 [00:02<00:00, 25.76it/s]Trainer is attempting to log a value of "{'accuracy': 0.8047904191616766}" of type <class 'dict'> for key "eval/accuracy" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.
Trainer is attempting to log a value of "{'precision': 0.8130096923522571}" of type <class 'dict'> for key "eval/precision" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.
Trainer is attempting to log a value of "{'recall': 0.8047904191616766}" of type <class 'dict'> for key "eval/recall" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:03<00:00, 25.95it/s]
