{'loss': 1.0992, 'grad_norm': 0.2167067676782608, 'learning_rate': 1.9592568448500654e-05, 'epoch': 0.08}                                                                
{'loss': 1.099, 'grad_norm': 0.4238165616989136, 'learning_rate': 1.9185136897001307e-05, 'epoch': 0.16}                                                                 
{'loss': 1.0992, 'grad_norm': 0.14053654670715332, 'learning_rate': 1.8777705345501956e-05, 'epoch': 0.24}                                                               
{'loss': 1.0914, 'grad_norm': 13.284025192260742, 'learning_rate': 1.837027379400261e-05, 'epoch': 0.33}                                                                 
{'loss': 1.0452, 'grad_norm': 1.9641873836517334, 'learning_rate': 1.796447196870926e-05, 'epoch': 0.41}                                                                 
{'loss': 0.9827, 'grad_norm': 2.439760446548462, 'learning_rate': 1.755704041720991e-05, 'epoch': 0.49}                                                                  
{'loss': 0.9321, 'grad_norm': 2.554187297821045, 'learning_rate': 1.7149608865710564e-05, 'epoch': 0.57}                                                                 
{'loss': 0.8697, 'grad_norm': 3.442716598510742, 'learning_rate': 1.6742177314211213e-05, 'epoch': 0.65}                                                                 
{'loss': 0.8332, 'grad_norm': 4.55739688873291, 'learning_rate': 1.6334745762711865e-05, 'epoch': 0.73}                                                                  
{'loss': 0.7927, 'grad_norm': 4.041698455810547, 'learning_rate': 1.5927314211212518e-05, 'epoch': 0.81}                                                                 
{'loss': 0.7777, 'grad_norm': 3.5455520153045654, 'learning_rate': 1.551988265971317e-05, 'epoch': 0.9}                                                                  
{'loss': 0.7478, 'grad_norm': 4.697306156158447, 'learning_rate': 1.511326597131682e-05, 'epoch': 0.98}                                                                  
 25%|███████████████████████████████▊                                                                                               | 6136/24544 [14:47<46:43,  6.57it/sTrainer is attempting to log a value of "{'accuracy': 0.6978043912175649}" of type <class 'dict'> for key "eval/accuracy" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.
Trainer is attempting to log a value of "{'precision': 0.7240378217550579}" of type <class 'dict'> for key "eval/precision" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.
Trainer is attempting to log a value of "{'recall': 0.6978043912175648}" of type <class 'dict'> for key "eval/recall" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.
{'eval_loss': 0.7439725995063782, 'eval_accuracy': {'accuracy': 0.6978043912175649}, 'eval_precision': {'precision': 0.7240378217550579}, 'eval_recall': {'recall': 0.6978043912175648}, 'eval_runtime': 3.0891, 'eval_samples_per_second': 1621.832, 'eval_steps_per_second': 25.574, 'epoch': 1.0}                                              
{'loss': 0.7203, 'grad_norm': 3.4667797088623047, 'learning_rate': 1.4705834419817473e-05, 'epoch': 1.06}                                                                
{'loss': 0.7117, 'grad_norm': 4.7842631340026855, 'learning_rate': 1.4298402868318124e-05, 'epoch': 1.14}                                                                
{'loss': 0.7026, 'grad_norm': 3.1181135177612305, 'learning_rate': 1.3890971316818776e-05, 'epoch': 1.22}                                                                
{'loss': 0.6899, 'grad_norm': 3.272463321685791, 'learning_rate': 1.3483539765319427e-05, 'epoch': 1.3}                                                                  
{'loss': 0.6898, 'grad_norm': 3.2834572792053223, 'learning_rate': 1.307610821382008e-05, 'epoch': 1.39}                                                                 
{'loss': 0.6824, 'grad_norm': 3.3767693042755127, 'learning_rate': 1.2668676662320732e-05, 'epoch': 1.47}                                                                
{'loss': 0.6762, 'grad_norm': 4.006897926330566, 'learning_rate': 1.2261245110821383e-05, 'epoch': 1.55}                                                                 
{'loss': 0.6663, 'grad_norm': 5.502870559692383, 'learning_rate': 1.1854628422425034e-05, 'epoch': 1.63}                                                                 
{'loss': 0.6628, 'grad_norm': 3.4432661533355713, 'learning_rate': 1.1448011734028684e-05, 'epoch': 1.71}                                                                
{'loss': 0.6521, 'grad_norm': 3.101728916168213, 'learning_rate': 1.1040580182529336e-05, 'epoch': 1.79}                                                                 
{'loss': 0.6504, 'grad_norm': 3.758293867111206, 'learning_rate': 1.0633148631029987e-05, 'epoch': 1.87}                                                                 
{'loss': 0.6497, 'grad_norm': 4.659458637237549, 'learning_rate': 1.022571707953064e-05, 'epoch': 1.96}                                                                  
 50%|███████████████████████████████████████████████████████████████                                                               | 12272/24544 [29:43<30:57,  6.61it/sTrainer is attempting to log a value of "{'accuracy': 0.7445109780439122}" of type <class 'dict'> for key "eval/accuracy" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.
Trainer is attempting to log a value of "{'precision': 0.7582037534863195}" of type <class 'dict'> for key "eval/precision" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.
Trainer is attempting to log a value of "{'recall': 0.7445109780439122}" of type <class 'dict'> for key "eval/recall" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.
{'eval_loss': 0.6281787753105164, 'eval_accuracy': {'accuracy': 0.7445109780439122}, 'eval_precision': {'precision': 0.7582037534863195}, 'eval_recall': {'recall': 0.7445109780439122}, 'eval_runtime': 3.0952, 'eval_samples_per_second': 1618.624, 'eval_steps_per_second': 25.523, 'epoch': 2.0}                                              
{'loss': 0.6293, 'grad_norm': 4.720165252685547, 'learning_rate': 9.818285528031292e-06, 'epoch': 2.04}                                                                  
{'loss': 0.6093, 'grad_norm': 3.641153573989868, 'learning_rate': 9.410853976531943e-06, 'epoch': 2.12}                                                                  
{'loss': 0.6117, 'grad_norm': 3.7952322959899902, 'learning_rate': 9.003422425032596e-06, 'epoch': 2.2}                                                                  
{'loss': 0.6081, 'grad_norm': 4.619126796722412, 'learning_rate': 8.595990873533247e-06, 'epoch': 2.28}                                                                  
{'loss': 0.5959, 'grad_norm': 3.9254186153411865, 'learning_rate': 8.189374185136898e-06, 'epoch': 2.36}                                                                 
{'loss': 0.6023, 'grad_norm': 3.902859687805176, 'learning_rate': 7.782757496740548e-06, 'epoch': 2.44}                                                                  
{'loss': 0.606, 'grad_norm': 3.5584962368011475, 'learning_rate': 7.375325945241199e-06, 'epoch': 2.53}                                                                  
{'loss': 0.6003, 'grad_norm': 5.2806830406188965, 'learning_rate': 6.967894393741852e-06, 'epoch': 2.61}                                                                 
{'loss': 0.5915, 'grad_norm': 4.522538185119629, 'learning_rate': 6.5604628422425045e-06, 'epoch': 2.69}                                                                 
{'loss': 0.6016, 'grad_norm': 5.497457504272461, 'learning_rate': 6.153846153846155e-06, 'epoch': 2.77}                                                                  
{'loss': 0.5897, 'grad_norm': 3.365842819213867, 'learning_rate': 5.746414602346806e-06, 'epoch': 2.85}                                                                  
{'loss': 0.5873, 'grad_norm': 3.399888277053833, 'learning_rate': 5.338983050847458e-06, 'epoch': 2.93}                                                                  
 75%|██████████████████████████████████████████████████████████████████████████████████████████████▌                               | 18408/24544 [44:12<14:25,  7.09it/sTrainer is attempting to log a value of "{'accuracy': 0.7554890219560878}" of type <class 'dict'> for key "eval/accuracy" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.
Trainer is attempting to log a value of "{'precision': 0.7681305430650663}" of type <class 'dict'> for key "eval/precision" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.
Trainer is attempting to log a value of "{'recall': 0.7554890219560878}" of type <class 'dict'> for key "eval/recall" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.
{'eval_loss': 0.6189595460891724, 'eval_accuracy': {'accuracy': 0.7554890219560878}, 'eval_precision': {'precision': 0.7681305430650663}, 'eval_recall': {'recall': 0.7554890219560878}, 'eval_runtime': 2.8847, 'eval_samples_per_second': 1736.743, 'eval_steps_per_second': 27.386, 'epoch': 3.0}                                              
{'loss': 0.5871, 'grad_norm': 3.698263168334961, 'learning_rate': 4.93155149934811e-06, 'epoch': 3.01}                                                                   
{'loss': 0.572, 'grad_norm': 4.509852409362793, 'learning_rate': 4.524119947848762e-06, 'epoch': 3.1}                                                                    
{'loss': 0.5614, 'grad_norm': 4.321457386016846, 'learning_rate': 4.1166883963494135e-06, 'epoch': 3.18}                                                                 
{'loss': 0.5639, 'grad_norm': 5.192122936248779, 'learning_rate': 3.7092568448500653e-06, 'epoch': 3.26}                                                                 
{'loss': 0.559, 'grad_norm': 3.4668161869049072, 'learning_rate': 3.3018252933507174e-06, 'epoch': 3.34}                                                                 
{'loss': 0.5554, 'grad_norm': 3.5963802337646484, 'learning_rate': 2.894393741851369e-06, 'epoch': 3.42}                                                                 
{'loss': 0.5608, 'grad_norm': 3.6873176097869873, 'learning_rate': 2.486962190352021e-06, 'epoch': 3.5}                                                                  
{'loss': 0.5599, 'grad_norm': 4.688539505004883, 'learning_rate': 2.079530638852673e-06, 'epoch': 3.59}                                                                  
{'loss': 0.5533, 'grad_norm': 4.745630741119385, 'learning_rate': 1.6729139504563236e-06, 'epoch': 3.67}                                                                 
{'loss': 0.5564, 'grad_norm': 4.637053966522217, 'learning_rate': 1.2654823989569754e-06, 'epoch': 3.75}                                                                 
{'loss': 0.5564, 'grad_norm': 3.8094210624694824, 'learning_rate': 8.580508474576271e-07, 'epoch': 3.83}                                                                 
{'loss': 0.5539, 'grad_norm': 3.462433338165283, 'learning_rate': 4.5061929595827906e-07, 'epoch': 3.91}                                                                 
{'loss': 0.5574, 'grad_norm': 3.8471572399139404, 'learning_rate': 4.31877444589309e-08, 'epoch': 3.99}                                                                  
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24544/24544 [58:56<00:00,  6.62it/sTrainer is attempting to log a value of "{'accuracy': 0.7596806387225549}" of type <class 'dict'> for key "eval/accuracy" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.
Trainer is attempting to log a value of "{'precision': 0.7702134545805713}" of type <class 'dict'> for key "eval/precision" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.
Trainer is attempting to log a value of "{'recall': 0.7596806387225549}" of type <class 'dict'> for key "eval/recall" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.
{'eval_loss': 0.6232099533081055, 'eval_accuracy': {'accuracy': 0.7596806387225549}, 'eval_precision': {'precision': 0.7702134545805713}, 'eval_recall': {'recall': 0.7596806387225549}, 'eval_runtime': 3.1102, 'eval_samples_per_second': 1610.833, 'eval_steps_per_second': 25.4, 'epoch': 4.0}                                                
{'train_runtime': 3540.6577, 'train_samples_per_second': 443.649, 'train_steps_per_second': 6.932, 'train_loss': 0.6947621536068376, 'epoch': 4.0}                       
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24544/24544 [59:00<00:00,  6.93it/s]
 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋   | 77/79 [00:02<00:00, 25.92it/s]Trainer is attempting to log a value of "{'accuracy': 0.7554890219560878}" of type <class 'dict'> for key "eval/accuracy" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.
Trainer is attempting to log a value of "{'precision': 0.7681305430650663}" of type <class 'dict'> for key "eval/precision" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.
Trainer is attempting to log a value of "{'recall': 0.7554890219560878}" of type <class 'dict'> for key "eval/recall" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:03<00:00, 26.09it/s]
